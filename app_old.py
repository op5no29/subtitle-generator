import os
import streamlit as st
import tempfile
import ffmpeg
import anthropic
from openai import OpenAI
from dotenv import load_dotenv
import pysrt
from datetime import timedelta
import json

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
claude_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

def extract_audio_from_video(video_path, audio_path):
    """å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º"""
    try:
        (
            ffmpeg
            .input(video_path)
            .output(audio_path, acodec='pcm_s16le', ar=16000, ac=1)
            .overwrite_output()
            .run(quiet=True)
        )
        return True
    except Exception as e:
        st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return False

def transcribe_with_whisper(audio_path, language="auto"):
    """Whisperã§éŸ³å£°èªè­˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰"""
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["word"]
            )
        return transcript
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def translate_with_claude(text, source_lang="è‹±èª", target_lang="æ—¥æœ¬èª"):
    """Claude APIã§ç¿»è¨³"""
    try:
        response = claude_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4000,
            messages=[{
                "role": "user",
                "content": f"""
ä»¥ä¸‹ã®{source_lang}ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãª{target_lang}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
- å‹•ç”»ã®å­—å¹•ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã€èª­ã¿ã‚„ã™ãçŸ­ã‚ã«
- å°‚é–€ç”¨èªã¯é©åˆ‡ã«ç¿»è¨³
- åŸæ–‡ã®æ„å‘³ã¨ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’ä¿æŒ

åŸæ–‡ï¼š
{text}
"""
            }]
        )
        return response.content[0].text
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        return text

def create_srt_from_transcript(transcript, translation):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãSRTãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
    subs = pysrt.SubRipFile()
    
    # wordså±æ€§ã‚’å®‰å…¨ã«å–å¾—
    words = getattr(transcript, 'words', []) if hasattr(transcript, 'words') else []
    if not words:
        # wordsãŒãªã„å ´åˆã¯å…¨ä½“ã‚’1ã¤ã®å­—å¹•ã«
        text_content = getattr(transcript, 'text', translation) if hasattr(transcript, 'text') else translation
        subs.append(pysrt.SubRipItem(
            index=1,
            start=pysrt.SubRipTime(0, 0, 0, 0),
            end=pysrt.SubRipTime(0, 0, 10, 0),
            text=text_content
        ))
        return subs
    
    # 10ç§’ã”ã¨ã«å­—å¹•ã‚’åˆ†å‰²
    current_text = ""
    start_time = 0
    subtitle_index = 1
    
    for i, word in enumerate(words):
        word_text = getattr(word, 'word', '') if hasattr(word, 'word') else str(word)
        word_start = getattr(word, 'start', i) if hasattr(word, 'start') else i
        word_end = getattr(word, 'end', i+1) if hasattr(word, 'end') else i+1
        
        current_text += word_text + " "
        
        # 10ç§’çµŒéã¾ãŸã¯æœ€å¾Œã®å˜èªã®å ´åˆ
        if word_end - start_time >= 10 or i == len(words) - 1:
            # ã“ã®éƒ¨åˆ†ã‚’ç¿»è¨³
            translated_segment = translate_with_claude(current_text.strip())
            
            subs.append(pysrt.SubRipItem(
                index=subtitle_index,
                start=pysrt.SubRipTime.from_ordinal(int(start_time * 1000)),
                end=pysrt.SubRipTime.from_ordinal(int(word_end * 1000)),
                text=translated_segment
            ))
            
            current_text = ""
            start_time = word_end
            subtitle_index += 1
    
    return subs

def embed_subtitles_to_video(video_path, srt_path, output_path):
    """å‹•ç”»ã«å­—å¹•ã‚’åŸ‹ã‚è¾¼ã¿"""
    try:
        (
            ffmpeg
            .input(video_path)
            .output(
                output_path,
                vf=f"subtitles={srt_path}:force_style='FontSize=20,PrimaryColour=&Hffffff&,OutlineColour=&H000000&,Outline=2'",
                acodec='copy'
            )
            .overwrite_output()
            .run(quiet=True)
        )
        return True
    except Exception as e:
        st.error(f"å­—å¹•åŸ‹ã‚è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# Streamlit UI
st.title("ğŸ¬ è‡ªå‹•å­—å¹•ç”Ÿæˆã‚¢ãƒ—ãƒª")
st.write("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è‡ªå‹•ã§æ—¥æœ¬èªå­—å¹•ã‚’ç”Ÿæˆã—ã¾ã™ï¼")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š
st.sidebar.header("è¨­å®š")
source_language = st.sidebar.selectbox(
    "å…ƒã®è¨€èª",
    ["auto", "en", "zh", "ko", "es", "fr"],
    format_func=lambda x: {
        "auto": "è‡ªå‹•æ¤œå‡º",
        "en": "è‹±èª",
        "zh": "ä¸­å›½èª",
        "ko": "éŸ“å›½èª",
        "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª"
    }[x]
)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(
    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=['mp4', 'mov', 'avi', 'mkv'],
    help="å¯¾å¿œå½¢å¼: MP4, MOV, AVI, MKV"
)

if uploaded_file is not None:
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    with tempfile.TemporaryDirectory() as temp_dir:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»ã‚’ä¿å­˜
        video_path = os.path.join(temp_dir, "input_video.mp4")
        with open(video_path, "wb") as f:
            f.write(uploaded_file.read())
        
        # å‹•ç”»æƒ…å ±è¡¨ç¤º
        st.video(uploaded_file)
        
        if st.button("ğŸš€ å­—å¹•ç”Ÿæˆé–‹å§‹"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Step 1: éŸ³å£°æŠ½å‡º
            status_text.text("ğŸ“„ å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
            progress_bar.progress(20)
            
            audio_path = os.path.join(temp_dir, "audio.wav")
            if not extract_audio_from_video(video_path, audio_path):
                st.stop()
            
            # Step 2: éŸ³å£°èªè­˜
            status_text.text("ğŸ¤ éŸ³å£°èªè­˜ä¸­...")
            progress_bar.progress(40)
            
            transcript = transcribe_with_whisper(audio_path, source_language)
            if not transcript:
                st.stop()
            
            # Step 3: ç¿»è¨³
            status_text.text("ğŸŒ ç¿»è¨³ä¸­...")
            progress_bar.progress(60)
            
            original_text = transcript.text if hasattr(transcript, 'text') else ''
            translated_text = translate_with_claude(original_text)
            
            # Step 4: å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            status_text.text("ğŸ“ å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
            progress_bar.progress(80)
            
            srt_content = create_srt_from_transcript(transcript, translated_text)
            srt_path = os.path.join(temp_dir, "subtitles.srt")
            srt_content.save(srt_path)
            
            # Step 5: å‹•ç”»ã«å­—å¹•åŸ‹ã‚è¾¼ã¿
            status_text.text("ğŸ¬ å‹•ç”»ã«å­—å¹•ã‚’åŸ‹ã‚è¾¼ã¿ä¸­...")
            progress_bar.progress(90)
            
            output_path = os.path.join(temp_dir, "output_with_subtitles.mp4")
            if embed_subtitles_to_video(video_path, srt_path, output_path):
                progress_bar.progress(100)
                status_text.text("âœ… å®Œäº†ï¼")
                
                # çµæœè¡¨ç¤º
                st.success("å­—å¹•ä»˜ãå‹•ç”»ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“„ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ")
                    st.text_area("", original_text, height=200)
                
                with col2:
                    st.subheader("ğŸŒ ç¿»è¨³çµæœ")
                    st.text_area("", translated_text, height=200)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                with open(output_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ å­—å¹•ä»˜ãå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name="subtitled_video.mp4",
                        mime="video/mp4"
                    )
                
                # SRTãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                with open(srt_path, "r", encoding="utf-8") as f:
                    st.download_button(
                        label="ğŸ“„ å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«(SRT)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name="subtitles.srt",
                        mime="text/plain"
                    )

# ä½¿ã„æ–¹èª¬æ˜
with st.expander("ğŸ“– ä½¿ã„æ–¹"):
    st.markdown("""
    1. **APIã‚­ãƒ¼è¨­å®š**: `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«OpenAIã¨Anthropicã®APIã‚­ãƒ¼ã‚’è¨­å®š
    2. **å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: å¯¾å¿œå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    3. **è¨€èªé¸æŠ**: å…ƒã®å‹•ç”»ã®è¨€èªã‚’é¸æŠï¼ˆè‡ªå‹•æ¤œå‡ºã‚‚å¯èƒ½ï¼‰
    4. **å®Ÿè¡Œ**: ã€Œå­—å¹•ç”Ÿæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    5. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ç”Ÿæˆã•ã‚ŒãŸå­—å¹•ä»˜ãå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    **å¯¾å¿œå½¢å¼**: MP4, MOV, AVI, MKV
    **å‡¦ç†æ™‚é–“**: å‹•ç”»ã®é•·ã•ã«å¿œã˜ã¦æ•°åˆ†ã€œæ•°ååˆ†
    """)

# æ³¨æ„äº‹é …
with st.expander("âš ï¸ æ³¨æ„äº‹é …"):
    st.markdown("""
    - **APIã‚³ã‚¹ãƒˆ**: é•·æ™‚é–“ã®å‹•ç”»ã¯æ–™é‡‘ãŒé«˜ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
    - **å‡¦ç†æ™‚é–“**: å‹•ç”»ã®é•·ã•ã«æ¯”ä¾‹ã—ã¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
    - **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
    - **ç²¾åº¦**: éŸ³è³ªã‚„è©±ã—æ–¹ã«ã‚ˆã‚Šèªè­˜ç²¾åº¦ãŒå¤‰ã‚ã‚Šã¾ã™
    """)
