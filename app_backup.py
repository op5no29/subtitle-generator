import os
import streamlit as st
import tempfile
import ffmpeg
import anthropic
from openai import OpenAI
from dotenv import load_dotenv
import pysrt
from datetime import timedelta
import json
import pyaudio
import wave
import time

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
claude_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

# è¨€èªè¨­å®š
LANGUAGES = {
    "auto": "è‡ªå‹•æ¤œå‡º",
    "ja": "æ—¥æœ¬èª",
    "en": "è‹±èª",
    "zh": "ä¸­å›½èª",
    "ko": "éŸ“å›½èª",
    "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
    "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
    "de": "ãƒ‰ã‚¤ãƒ„èª",
    "it": "ã‚¤ã‚¿ãƒªã‚¢èª",
    "pt": "ãƒãƒ«ãƒˆã‚¬ãƒ«èª",
    "ru": "ãƒ­ã‚·ã‚¢èª",
    "unknown": "è¨€èªä¸æ˜"
}

TARGET_LANGUAGES = {
    "ja": "æ—¥æœ¬èª",
    "en": "è‹±èª",
    "zh": "ä¸­å›½èª",
    "ko": "éŸ“å›½èª",
    "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
    "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª"
}

def extract_audio_from_video(video_path, audio_path):
    """å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º"""
    try:
        (
            ffmpeg
            .input(video_path)
            .output(audio_path, acodec='pcm_s16le', ar=16000, ac=1)
            .overwrite_output()
            .run(quiet=True)
        )
        return True
    except Exception as e:
        st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return False

def transcribe_with_whisper(audio_path, language="auto"):
    """Whisperã§éŸ³å£°èªè­˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ»è¨€èªæ¤œå‡ºæƒ…å ±ä»˜ãï¼‰"""
    try:
        with open(audio_path, "rb") as audio_file:
            # languageãŒ"auto"ã¾ãŸã¯"unknown"ã®å ´åˆã¯languageãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’çœç•¥
            if language in ["auto", "unknown"]:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["word"]
                )
            else:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language,
                    response_format="verbose_json",
                    timestamp_granularities=["word"]
                )
        return transcript
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def translate_with_claude(text, source_lang="auto", target_lang="ja"):
    """Claude APIã§ç¿»è¨³ï¼ˆæ–‡è„ˆé‡è¦–ãƒ»æ”¹è‰¯ç‰ˆï¼‰"""
    try:
        # åŒã˜è¨€èªã®å ´åˆã¯ç¿»è¨³ã›ãšãã®ã¾ã¾è¿”ã™
        if source_lang == target_lang:
            return text
        
        # ã‚ˆã‚Šç°¡æ½”ã§æ–‡è„ˆã‚’é‡è¦–ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        if target_lang == "ja":
            target_name = "æ—¥æœ¬èª"
        elif target_lang == "en":
            target_name = "è‹±èª"
        elif target_lang == "zh":
            target_name = "ä¸­å›½èª"
        else:
            target_name = TARGET_LANGUAGES.get(target_lang, "æ—¥æœ¬èª")
        
        response = claude_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4000,
            messages=[{
                "role": "user",
                "content": f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãª{target_name}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªæŒ‡ç¤ºï¼š
- æ–‡è„ˆã¨ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’é‡è¦–ã—ã€å…¨ä½“ã®æµã‚Œã‚’è€ƒæ…®ã—ã¦ãã ã•ã„
- ç›´è¨³ã§ã¯ãªãã€{target_name}ã¨ã—ã¦è‡ªç„¶ãªè¡¨ç¾ã«ã—ã¦ãã ã•ã„
- å°‚é–€ç”¨èªã‚„å›ºæœ‰åè©ã¯é©åˆ‡ã«ç¿»è¨³ã—ã¦ãã ã•ã„
- è©±ã—è¨€è‘‰ã®å ´åˆã¯{target_name}ã®è©±ã—è¨€è‘‰ã¨ã—ã¦è‡ªç„¶ã«ã—ã¦ãã ã•ã„
- å…ƒã®æ„å‘³ã¨ãƒˆãƒ¼ãƒ³ã‚’ä¿æŒã—ã¦ãã ã•ã„
- ç¿»è¨³çµæœã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ï¼‰

ç¿»è¨³å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆï¼š
{text}"""
            }]
        )
        return response.content[0].text.strip()
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        return text

def split_text_for_subtitles(text, max_chars_per_line=20, max_lines=2):
    """å­—å¹•ç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«åˆ†å‰²"""
    # å¥èª­ç‚¹ã§åˆ†å‰²
    sentences = []
    current_sentence = ""
    
    for char in text:
        current_sentence += char
        if char in 'ã€‚ï¼ï¼Ÿã€.:!?':
            sentences.append(current_sentence.strip())
            current_sentence = ""
    
    if current_sentence.strip():
        sentences.append(current_sentence.strip())
    
    # çŸ­ã„ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk + sentence) <= max_chars_per_line * max_lines:
            current_chunk += sentence
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    # è¡Œåˆ†å‰²
    final_chunks = []
    for chunk in chunks:
        if len(chunk) <= max_chars_per_line:
            final_chunks.append(chunk)
        else:
            # é•·ã„å ´åˆã¯æ”¹è¡Œã§åˆ†å‰²
            words = chunk.split()
            lines = []
            current_line = ""
            
            for word in words:
                if len(current_line + word) <= max_chars_per_line:
                    current_line += word + " "
                else:
                    if current_line:
                        lines.append(current_line.strip())
                    current_line = word + " "
            
            if current_line:
                lines.append(current_line.strip())
            
            # æœ€å¤§2è¡Œã¾ã§
            if len(lines) <= max_lines:
                final_chunks.append('\n'.join(lines))
            else:
                # 2è¡Œãšã¤ã«åˆ†å‰²
                for i in range(0, len(lines), max_lines):
                    final_chunks.append('\n'.join(lines[i:i+max_lines]))
    
    return final_chunks

def create_srt_from_transcript(transcript, translation, source_lang, target_lang):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãSRTãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    subs = pysrt.SubRipFile()
    
    # wordså±æ€§ã‚’å®‰å…¨ã«å–å¾—
    words = getattr(transcript, 'words', []) if hasattr(transcript, 'words') else []
    if not words:
        # wordsãŒãªã„å ´åˆã¯ç¿»è¨³ã‚’é©åˆ‡ã«åˆ†å‰²
        if source_lang != target_lang:
            text_content = translate_with_claude(transcript.text if hasattr(transcript, 'text') else '', source_lang, target_lang)
        else:
            text_content = transcript.text if hasattr(transcript, 'text') else translation
        
        chunks = split_text_for_subtitles(text_content)
        duration_per_chunk = 10 / len(chunks) if chunks else 10
        
        for i, chunk in enumerate(chunks):
            subs.append(pysrt.SubRipItem(
                index=i+1,
                start=pysrt.SubRipTime.from_ordinal(int(i * duration_per_chunk * 1000)),
                end=pysrt.SubRipTime.from_ordinal(int((i + 1) * duration_per_chunk * 1000)),
                text=chunk
            ))
        return subs
    
    # 3-5ç§’ã”ã¨ã«å­—å¹•ã‚’åˆ†å‰²ï¼ˆçŸ­ç¸®ï¼‰
    current_text = ""
    start_time = 0
    subtitle_index = 1
    
    for i, word in enumerate(words):
        word_text = getattr(word, 'word', '') if hasattr(word, 'word') else str(word)
        word_start = getattr(word, 'start', i) if hasattr(word, 'start') else i
        word_end = getattr(word, 'end', i+1) if hasattr(word, 'end') else i+1
        
        current_text += word_text + " "
        
        # 3-5ç§’çµŒéã€å¥èª­ç‚¹ã€ã¾ãŸã¯æœ€å¾Œã®å˜èªã®å ´åˆ
        duration = word_end - start_time
        is_sentence_end = word_text.strip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ã€'))
        is_time_limit = duration >= 3
        is_last_word = i == len(words) - 1
        
        if is_time_limit or is_sentence_end or is_last_word:
            # ã“ã®éƒ¨åˆ†ã‚’ç¿»è¨³
            if source_lang != target_lang:
                translated_segment = translate_with_claude(current_text.strip(), source_lang, target_lang)
            else:
                translated_segment = current_text.strip()
            
            # é•·ã„å ´åˆã¯åˆ†å‰²
            subtitle_chunks = split_text_for_subtitles(translated_segment)
            chunk_duration = (word_end - start_time) / len(subtitle_chunks) if subtitle_chunks else 3
            
            for j, chunk in enumerate(subtitle_chunks):
                chunk_start = start_time + (j * chunk_duration)
                chunk_end = start_time + ((j + 1) * chunk_duration)
                
                subs.append(pysrt.SubRipItem(
                    index=subtitle_index,
                    start=pysrt.SubRipTime.from_ordinal(int(chunk_start * 1000)),
                    end=pysrt.SubRipTime.from_ordinal(int(chunk_end * 1000)),
                    text=chunk
                ))
                subtitle_index += 1
            
            current_text = ""
            start_time = word_end
    
def create_srt_from_transcript_custom(transcript, translation, source_lang, target_lang, max_chars_per_line=20, max_lines=2):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãSRTãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆè‡ªç„¶ãªåŒºåˆ‡ã‚Šé‡è¦–ï¼‰"""
    subs = pysrt.SubRipFile()
    
    # WhisperãŒå®Ÿéš›ã«æ¤œå‡ºã—ãŸè¨€èªã‚’å–å¾—
    detected_language = getattr(transcript, 'language', source_lang)
    actual_source_lang = detected_language if source_lang == "auto" else source_lang
    
    # ç¿»è¨³ã®å¿…è¦æ€§ã‚’åˆ¤å®šï¼ˆå®Ÿéš›ã®æ¤œå‡ºè¨€èªãƒ™ãƒ¼ã‚¹ï¼‰
    need_translation = not (
        actual_source_lang == target_lang or
        (actual_source_lang == "ja" and target_lang == "ja") or
        (actual_source_lang == "japanese" and target_lang == "ja")  # Whisperã¯"japanese"ã‚’è¿”ã™ã“ã¨ãŒã‚ã‚‹
    )
    
    # å…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    full_text = transcript.text if hasattr(transcript, 'text') else ''
    
    # ç¿»è¨³ãŒå¿…è¦ãªå ´åˆã¯ã€å…¨ä½“ã‚’ä¸€åº¦ã«ç¿»è¨³ï¼ˆæ–‡è„ˆä¿æŒï¼‰
    if need_translation and full_text.strip():
        st.info("ğŸŒ å…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ç¿»è¨³ä¸­...")
        full_translated_text = translate_with_claude(full_text, actual_source_lang, target_lang)
    else:
        full_translated_text = full_text
    
    # wordså±æ€§ã‚’å®‰å…¨ã«å–å¾—
    words = getattr(transcript, 'words', []) if hasattr(transcript, 'words') else []
    
    if not words:
        # wordsãŒãªã„å ´åˆã¯ç¿»è¨³æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ã«åˆ†å‰²
        chunks = split_text_for_subtitles(full_translated_text, max_chars_per_line, max_lines)
        # é©åˆ‡ãªè¡¨ç¤ºæ™‚é–“ã‚’è¨ˆç®—ï¼ˆèª­ã‚€æ™‚é–“ã‚’è€ƒæ…®ï¼‰
        total_duration = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30ç§’
        duration_per_chunk = max(2, total_duration / len(chunks)) if chunks else 3
        
        for i, chunk in enumerate(chunks):
            subs.append(pysrt.SubRipItem(
                index=i+1,
                start=pysrt.SubRipTime.from_ordinal(int(i * duration_per_chunk * 1000)),
                end=pysrt.SubRipTime.from_ordinal(int((i + 1) * duration_per_chunk * 1000)),
                text=chunk
            ))
        return subs
    
    # å˜èªãƒ¬ãƒ™ãƒ«ã®æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼šè‡ªç„¶ãªåŒºåˆ‡ã‚Šã§å­—å¹•åˆ†å‰²
    st.info("ğŸ“ éŸ³å£°ã®è‡ªç„¶ãªåŒºåˆ‡ã‚Šã«åˆã‚ã›ã¦å­—å¹•ã‚’ä½œæˆä¸­...")
    
    # è‡ªç„¶ãªåŒºåˆ‡ã‚Šãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹
    natural_segments = find_natural_segments(words, full_translated_text)
    
    # å­—å¹•ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä½œæˆ
    subtitle_index = 1
    for segment in natural_segments:
        # é•·ã„å ´åˆã¯ã•ã‚‰ã«åˆ†å‰²
        subtitle_chunks = split_text_for_subtitles(segment['translated_text'], max_chars_per_line, max_lines)
        
        if len(subtitle_chunks) == 1:
            # 1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆ
            subs.append(pysrt.SubRipItem(
                index=subtitle_index,
                start=pysrt.SubRipTime.from_ordinal(int(segment['start'] * 1000)),
                end=pysrt.SubRipTime.from_ordinal(int(segment['end'] * 1000)),
                text=subtitle_chunks[0]
            ))
            subtitle_index += 1
        else:
            # è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆã¯æ™‚é–“ã‚’åˆ†å‰²
            chunk_duration = (segment['end'] - segment['start']) / len(subtitle_chunks)
            for j, chunk in enumerate(subtitle_chunks):
                chunk_start = segment['start'] + (j * chunk_duration)
                chunk_end = segment['start'] + ((j + 1) * chunk_duration)
                
                subs.append(pysrt.SubRipItem(
                    index=subtitle_index,
                    start=pysrt.SubRipTime.from_ordinal(int(chunk_start * 1000)),
                    end=pysrt.SubRipTime.from_ordinal(int(chunk_end * 1000)),
                    text=chunk
                ))
                subtitle_index += 1
    
    return subs

def find_natural_segments(words, translated_text):
    """éŸ³å£°ã®è‡ªç„¶ãªåŒºåˆ‡ã‚Šã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ"""
    segments = []
    current_words = []
    current_original_text = ""
    segment_start = 0
    
    for i, word in enumerate(words):
        word_text = getattr(word, 'word', '') if hasattr(word, 'word') else str(word)
        word_start = getattr(word, 'start', i) if hasattr(word, 'start') else i
        word_end = getattr(word, 'end', i+1) if hasattr(word, 'end') else i+1
        
        if i == 0:
            segment_start = word_start
        
        current_words.append(word)
        current_original_text += word_text + " "
        
        # è‡ªç„¶ãªåŒºåˆ‡ã‚Šãƒã‚¤ãƒ³ãƒˆã‚’åˆ¤å®š
        is_sentence_end = word_text.strip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?'))
        is_pause_after = False
        
        # æ¬¡ã®å˜èªã¨ã®é–“ã«é•·ã„ãƒãƒ¼ã‚ºãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if i < len(words) - 1:
            next_word = words[i + 1]
            next_start = getattr(next_word, 'start', i+1)
            pause_duration = next_start - word_end
            is_pause_after = pause_duration > 1.0  # 1ç§’ä»¥ä¸Šã®ãƒãƒ¼ã‚º
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        segment_duration = word_end - segment_start
        is_long_segment = segment_duration > 6.0  # 6ç§’ä»¥ä¸Šã®é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        
        # æœ€å¾Œã®å˜èª
        is_last_word = i == len(words) - 1
        
        # åŒºåˆ‡ã‚Šæ¡ä»¶
        should_break = (
            (is_sentence_end and segment_duration >= 1.5) or  # æ–‡çµ‚äº†ã‹ã¤æœ€ä½1.5ç§’
            (is_pause_after and segment_duration >= 2.0) or   # é•·ã„ãƒãƒ¼ã‚ºã‹ã¤æœ€ä½2ç§’
            is_long_segment or                                # é•·ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
            is_last_word                                      # æœ€å¾Œã®å˜èª
        )
        
        if should_break:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
            original_segment_text = current_original_text.strip()
            
            # ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¯¾å¿œã™ã‚‹éƒ¨åˆ†ã‚’æ¨å®š
            translated_segment = estimate_translated_segment(
                original_segment_text,
                translated_text,
                len(segments),
                len([w for w in words if getattr(w, 'start', 0) <= word_end])
            )
            
            segments.append({
                'start': segment_start,
                'end': word_end,
                'original_text': original_segment_text,
                'translated_text': translated_segment
            })
            
            # æ¬¡ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æº–å‚™
            current_words = []
            current_original_text = ""
            if not is_last_word:
                segment_start = word_end
    
    return segments

def estimate_translated_segment(original_text, full_translated_text, segment_index, total_segments):
    """ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¯¾å¿œã™ã‚‹éƒ¨åˆ†ã‚’æ¨å®š"""
    # ç°¡å˜ãªå®Ÿè£…ï¼šç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥èª­ç‚¹ã§åˆ†å‰²
    import re
    
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?]+', full_translated_text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if not sentences:
        return original_text
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹æ–‡ã‚’é¸æŠ
    if segment_index < len(sentences):
        result = sentences[segment_index]
        # å¥èª­ç‚¹ã‚’å¾©å…ƒ
        if segment_index < len(sentences) - 1:
            result += "ã€‚"
        return result
    else:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ–‡ã‚ˆã‚Šå¤šã„å ´åˆã¯æ¯”ä¾‹é…åˆ†
        proportion = segment_index / max(total_segments, 1)
        char_position = int(len(full_translated_text) * proportion)
        
        # é©åˆ‡ãªåˆ†å‰²ç‚¹ã‚’æ¢ã™
        start_pos = max(0, char_position - 50)
        end_pos = min(len(full_translated_text), char_position + 50)
        
        # å¥èª­ç‚¹ã§åŒºåˆ‡ã‚‹
        for i in range(char_position, end_pos):
            if full_translated_text[i] in 'ã€‚ï¼ï¼Ÿ':
                return full_translated_text[start_pos:i+1].strip()
        
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æ–‡å­—æ•°ã§åˆ‡ã‚‹
        return full_translated_text[start_pos:end_pos].strip()

def embed_subtitles_to_video_custom(video_path, srt_path, output_path, font_size=16, margin_bottom=20, outline_width=2):
    """å‹•ç”»ã«å­—å¹•ã‚’åŸ‹ã‚è¾¼ã¿ï¼ˆã‚«ã‚¹ã‚¿ãƒ è¨­å®šå¯¾å¿œï¼‰"""
    try:
        # å­—å¹•ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
        subtitle_style = (
            f"subtitles={srt_path}:"
            "force_style='"
            "FontName=Arial,"
            f"FontSize={font_size},"
            "PrimaryColour=&Hffffff&,"  # ç™½æ–‡å­—
            "OutlineColour=&H000000&,"  # é»’ç¸å–ã‚Š
            f"Outline={outline_width},"
            "Shadow=1,"  # å½±
            "Alignment=2,"  # ä¸‹éƒ¨ä¸­å¤®æƒãˆ
            f"MarginV={margin_bottom},"  # ä¸‹ç«¯ã‹ã‚‰ã®ä½™ç™½
            "MarginL=20,"  # å·¦ä½™ç™½
            "MarginR=20,"  # å³ä½™ç™½
            "BorderStyle=1"  # ç¸å–ã‚Šã‚¹ã‚¿ã‚¤ãƒ«
            "'"
        )
        
        (
            ffmpeg
            .input(video_path)
            .output(
                output_path,
                vf=subtitle_style,
                acodec='copy'
            )
            .overwrite_output()
            .run(quiet=True)
        )
        return True
    except Exception as e:
        st.error(f"å­—å¹•åŸ‹ã‚è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ç”¨ã®é–¢æ•°
def test_realtime_audio():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    try:
        import pyaudio
        import struct
        import time
        
        # éŸ³å£°è¨­å®šï¼ˆãƒãƒƒãƒ•ã‚¡ã‚’å¤§ããã—ã¦ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
        FORMAT = pyaudio.paInt16
        CHANNELS = 1
        RATE = 16000
        CHUNK = 4096  # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’å¤§ããï¼ˆ1024â†’4096ï¼‰
        
        audio = pyaudio.PyAudio()
        
        # éŒ²éŸ³é–‹å§‹
        stream = audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK,
            input_device_index=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨
        )
        
        st.info("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼è©±ã—ã¦ã¿ã¦ãã ã•ã„...")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        level_placeholder = st.empty()
        progress_placeholder = st.empty()
        
        max_level = 0
        test_duration = 10  # 10ç§’é–“ãƒ†ã‚¹ãƒˆ
        update_interval = 0.2  # æ›´æ–°é–“éš”ã‚’é•·ãï¼ˆ0.1â†’0.2ç§’ï¼‰
        
        total_chunks = int(RATE / CHUNK * test_duration)
        
        for i in range(total_chunks):
            try:
                # éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°èª­ã¿è¾¼ã¿
                if stream.get_read_available() >= CHUNK:
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    
                    # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
                    try:
                        samples = struct.unpack('<' + ('h' * (len(data) // 2)), data)
                        amplitude = max(abs(sample) for sample in samples)
                        current_level = amplitude
                        max_level = max(max_level, current_level)
                        
                        # 5å›ã«1å›ã ã‘è¡¨ç¤ºæ›´æ–°ï¼ˆè² è·è»½æ¸›ï¼‰
                        if i % 5 == 0:
                            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤º
                            progress = min(current_level / 30000, 1.0)  # 30000ã‚’æœ€å¤§å€¤ã¨ã—ã¦æ­£è¦åŒ–
                            progress_placeholder.progress(progress)
                            
                            # æ•°å€¤ã§ã‚‚è¡¨ç¤º
                            level_placeholder.metric(
                                "ğŸ¤ ç¾åœ¨ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«",
                                f"{current_level:,}",
                                f"æœ€å¤§: {max_level:,}"
                            )
                    except struct.error:
                        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸æ•´åˆã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                        continue
                        
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å°‘ã—å¾…ã¤
                    time.sleep(0.01)
                
                # æ›´æ–°é–“éš”ã‚’èª¿æ•´
                time.sleep(update_interval)
                
            except IOError as e:
                if e.errno == -9981:  # Input overflowed
                    st.warning("âš ï¸ éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã€‚ç¶šè¡Œä¸­...")
                    continue
                else:
                    raise e
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        # æœ€çµ‚è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
        level_placeholder.empty()
        progress_placeholder.empty()
        
        # çµæœè©•ä¾¡
        if max_level > 10000:
            st.success(f"âœ… éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£æˆåŠŸï¼æœ€å¤§ãƒ¬ãƒ™ãƒ«: {max_level:,}")
            st.info("ğŸ’¡ ã“ã®å€¤ãªã‚‰éŸ³å£°èªè­˜ã«ååˆ†ã§ã™")
        elif max_level > 1000:
            st.warning(f"âš ï¸ éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒä½ã‚ã§ã™: {max_level:,}")
            st.info("ğŸ’¡ ã‚‚ã†å°‘ã—å¤§ããªå£°ã§è©±ã™ã‹ã€ãƒã‚¤ã‚¯ã«è¿‘ã¥ã„ã¦ãã ã•ã„")
        else:
            st.error(f"âŒ éŸ³å£°ãŒã»ã¨ã‚“ã©æ¤œå‡ºã•ã‚Œã¾ã›ã‚“: {max_level:,}")
            st.error("ğŸ’¡ ãƒã‚¤ã‚¯ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
        return max_level > 1000
        
    except Exception as e:
        st.error(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        st.info("ğŸ’¡ Macã®å ´åˆã€ä»¥ä¸‹ã‚’è©¦ã—ã¦ãã ã•ã„ï¼š")
        st.info("- ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ > ãƒã‚¤ã‚¯ ã§æ¨©é™ç¢ºèª")
        st.info("- ä»–ã®ã‚¢ãƒ—ãƒªãŒãƒã‚¤ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ã‹ç¢ºèª")
        st.info("- å†…è”µãƒã‚¤ã‚¯ã®éŸ³é‡ã‚’ä¸Šã’ã‚‹")
        return False

def capture_audio_chunk(source_language="ja", target_language="ja"):
    """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦å‡¦ç†ï¼ˆè¨€èªè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    try:
        import pyaudio
        import wave
        import tempfile
        import time
        import os
        import struct
        
        st.info("ğŸ”§ ãƒ‡ãƒãƒƒã‚°: éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’é–‹å§‹ã—ã¾ã™...")
        st.info(f"ğŸŒ è¨­å®š: {LANGUAGES.get(source_language, source_language)} â†’ {TARGET_LANGUAGES.get(target_language, target_language)}")
        
        # éŸ³å£°è¨­å®šï¼ˆãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
        FORMAT = pyaudio.paInt16
        CHANNELS = 1
        RATE = 16000
        CHUNK = 4096  # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’å¤§ãã
        RECORD_SECONDS = 5  # 5ç§’é–“éŒ²éŸ³
        
        audio = pyaudio.PyAudio()
        
        # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯
        device_count = audio.get_device_count()
        default_input = audio.get_default_input_device_info()
        st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")
        st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹: {default_input['name']}")
        
        # éŒ²éŸ³é–‹å§‹ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
        stream = audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK,
            input_device_index=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒã‚¤ã‚¹
        )
        
        st.info("ğŸ¤ 5ç§’é–“éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã™... **å¤§ããªå£°ã§è©±ã—ã¦ãã ã•ã„ï¼**")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨
        level_placeholder = st.empty()
        progress_placeholder = st.empty()
        
        frames = []
        max_amplitude = 0
        
        # éŒ²éŸ³ãƒ«ãƒ¼ãƒ—ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
        total_chunks = int(RATE / CHUNK * RECORD_SECONDS)
        
        for i in range(total_chunks):
            try:
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’ç„¡è¦–ã—ã¦éŒ²éŸ³
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼ˆè»½é‡åŒ–ï¼‰
                if i % 3 == 0:  # 3å›ã«1å›ã ã‘æ›´æ–°
                    try:
                        samples = struct.unpack('<' + ('h' * (len(data) // 2)), data)
                        current_level = max(abs(sample) for sample in samples)
                        max_amplitude = max(max_amplitude, current_level)
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¡¨ç¤º
                        progress = min(current_level / 30000, 1.0)
                        progress_placeholder.progress(progress)
                        level_placeholder.write(f"ğŸ¤ ç¾åœ¨: {current_level:,} | æœ€å¤§: {max_amplitude:,}")
                    except (struct.error, ValueError):
                        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—
                        continue
                        
            except IOError as e:
                if e.errno == -9981:  # Input overflowed
                    # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®å ´åˆã¯ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    silence = b'\x00' * (CHUNK * 2)  # 16bit = 2bytes
                    frames.append(silence)
                    continue
                else:
                    raise e
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        # æœ€çµ‚çš„ãªãƒ¬ãƒ™ãƒ«è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
        level_placeholder.empty()
        progress_placeholder.empty()
        
        st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: æœ€å¤§éŸ³å£°ãƒ¬ãƒ™ãƒ«: {max_amplitude:,} (10000ä»¥ä¸ŠãŒç†æƒ³)")
        
        if max_amplitude < 1000:
            st.warning("âš ï¸ éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒä½ã™ãã¾ã™ã€‚ãƒã‚¤ã‚¯ã«è¿‘ã¥ã„ã¦å¤§ããªå£°ã§è©±ã—ã¦ãã ã•ã„")
        
        st.info("ğŸ”„ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
            temp_path = temp_audio.name
            
            wf = wave.open(temp_path, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            file_size = os.path.getsize(temp_path)
            st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®é–¾å€¤ã‚’èª¿æ•´ï¼ˆCHUNKãŒå¤§ãããªã£ãŸãŸã‚ï¼‰
            min_file_size = RATE * 2 * RECORD_SECONDS * 0.5  # æœŸå¾…ã‚µã‚¤ã‚ºã®50%ä»¥ä¸Š
            
            if file_size < min_file_size:
                st.warning(f"âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå°ã•ã‚ã§ã™ï¼ˆ{file_size:,} bytes < {min_file_size:,} bytesï¼‰")
                st.info("ğŸ’¡ éŸ³å£°ãŒå°ã•ã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            
            st.info("ğŸ¤– Whisper APIã§æ–‡å­—èµ·ã“ã—ä¸­...")
            
            try:
                # Whisperã§æ–‡å­—èµ·ã“ã—ï¼ˆè¨€èªæŒ‡å®šï¼‰
                with open(temp_path, "rb") as audio_file:
                    if source_language in ["auto", "unknown"]:
                        # è¨€èªè‡ªå‹•æ¤œå‡º
                        transcript = openai_client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            response_format="text"
                        )
                    else:
                        # è¨€èªæŒ‡å®š
                        transcript = openai_client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            language=source_language,
                            response_format="text"
                        )
                
                st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: Whisperç”Ÿã®çµæœ: '{transcript}'")
                st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: æ–‡å­—æ•°: {len(transcript)} æ–‡å­—")
                
                if transcript.strip():
                    st.success(f"ğŸ¯ èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: '{transcript.strip()}'")
                    
                    # ç¿»è¨³åˆ¤å®šï¼šåŒã˜è¨€èªã¾ãŸã¯æ—¥æœ¬èªâ†’æ—¥æœ¬èªã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    need_translation = not (
                        source_language == target_language or
                        (source_language == "ja" and target_language == "ja") or
                        (source_language == "auto" and target_language == "ja")
                    )
                    
                    if need_translation:
                        st.info("ğŸŒ Claude APIã§ç¿»è¨³ä¸­...")
                        translated = translate_with_claude(transcript.strip(), source_language, target_language)
                        st.info(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°: ç¿»è¨³çµæœ: '{translated}'")
                    else:
                        st.info("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å…ƒã®å“è³ªã‚’ä¿æŒã—ã¾ã™")
                        translated = transcript.strip()
                    
                    # å±¥æ­´ã«è¿½åŠ ï¼ˆç¢ºå®Ÿã«æ›´æ–°ï¼‰
                    new_entry = {
                        "timestamp": time.strftime("%H:%M:%S"),
                        "original": transcript_text.strip(),
                        "translated": translated,
                        "source_lang": LANGUAGES.get(actual_source_lang, actual_source_lang),
                        "target_lang": TARGET_LANGUAGES.get(target_language, target_language),
                        "was_translated": need_translation,
                        "detected_lang": detected_language  # å®Ÿéš›ã®æ¤œå‡ºè¨€èªã‚‚ä¿å­˜
                    }
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆå¿µã®ãŸã‚ï¼‰
                    if 'transcription_history' not in st.session_state:
                        st.session_state.transcription_history = []
                    
                    # å±¥æ­´ã«è¿½åŠ 
                    st.session_state.transcription_history.append(new_entry)
                    
                    st.success(f"âœ… éŸ³å£°èªè­˜å®Œäº†ï¼å±¥æ­´ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸï¼ˆç·æ•°: {len(st.session_state.transcription_history)}ï¼‰")
                    
                    # çµæœã‚’å³åº§ã«è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    st.write("**è¿½åŠ ã•ã‚ŒãŸçµæœ:**")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"å…ƒã®éŸ³å£°: {new_entry['original']}")
                        if source_language == "auto":
                            st.caption(f"æ¤œå‡ºè¨€èª: {new_entry['source_lang']} ({detected_language})")
                        else:
                            st.caption(f"è¨€èª: {new_entry['source_lang']}")
                    with col2:
                        if need_translation:
                            st.write(f"ç¿»è¨³çµæœ: {new_entry['translated']}")
                            st.caption(f"ç¿»è¨³å…ˆ: {new_entry['target_lang']}")
                        else:
                            st.write(f"çµæœ: {new_entry['translated']}")
                            st.caption("ç¿»è¨³ãªã—ï¼ˆå“è³ªä¿æŒï¼‰")
                    
                else:
                    st.warning("âš ï¸ Whisper APIã‹ã‚‰ç©ºã®çµæœãŒè¿”ã•ã‚Œã¾ã—ãŸ")
                    st.info("ğŸ’¡ ä»¥ä¸‹ã‚’è©¦ã—ã¦ãã ã•ã„ï¼š")
                    st.info("- ã‚ˆã‚Šå¤§ããªå£°ã§è©±ã™")
                    st.info("- ãƒã‚¤ã‚¯ã«è¿‘ã¥ã")
                    st.info("- èƒŒæ™¯ãƒã‚¤ã‚ºã‚’æ¸›ã‚‰ã™")
                    return False
                
            except Exception as whisper_error:
                st.error(f"âŒ Whisper API ã‚¨ãƒ©ãƒ¼: {whisper_error}")
                import traceback
                st.error(f"è©³ç´°: {traceback.format_exc()}")
                return False
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(temp_path)
            return True
            
    except Exception as e:
        st.error(f"âŒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã«å¿œã˜ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹
        if "Input overflowed" in str(e):
            st.error("ğŸ’¡ éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼š")
            st.info("- ä»–ã®ã‚¢ãƒ—ãƒªï¼ˆZoomã€Teamsç­‰ï¼‰ã‚’çµ‚äº†ã—ã¦ãƒã‚¤ã‚¯ã‚’è§£æ”¾")
            st.info("- ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®šã§ãƒã‚¤ã‚¯éŸ³é‡ã‚’ä¸‹ã’ã‚‹")
            st.info("- ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œ")
        elif "Invalid device" in str(e):
            st.error("ğŸ’¡ ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹å•é¡Œï¼š")
            st.info("- ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ã‚µã‚¦ãƒ³ãƒ‰ ã§æ­£ã—ã„ãƒã‚¤ã‚¯ã‚’é¸æŠ")
            st.info("- å¤–éƒ¨ãƒã‚¤ã‚¯ã®æ¥ç¶šã‚’ç¢ºèª")
        else:
            st.error("ğŸ’¡ ä¸€èˆ¬çš„ãªå¯¾å‡¦æ³•ï¼š")
            st.info("- ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•")
            st.info("- ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å†èµ·å‹•")
            st.info("- ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ > ãƒã‚¤ã‚¯ ã§æ¨©é™ç¢ºèª")
        
        import traceback
        st.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

# Streamlit UI
st.title("ğŸ¬ å¤šæ©Ÿèƒ½è‡ªå‹•å­—å¹•ç”Ÿæˆã‚¢ãƒ—ãƒª")

# ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†å‰²
tab1, tab2 = st.tabs(["ğŸ“¹ å‹•ç”»å­—å¹•ç”Ÿæˆ", "ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜"])

with tab1:
    st.write("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è‡ªå‹•ã§å­—å¹•ã‚’ç”Ÿæˆã—ã¾ã™ï¼")
    
    # è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("âš™ï¸ åŸºæœ¬è¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        source_language = st.selectbox(
            "å…ƒã®è¨€èª",
            list(LANGUAGES.keys()),
            format_func=lambda x: LANGUAGES[x],
            index=0
        )
    
    with col2:
        target_language = st.selectbox(
            "ç¿»è¨³å…ˆè¨€èª",
            list(TARGET_LANGUAGES.keys()),
            format_func=lambda x: TARGET_LANGUAGES[x],
            index=0
        )
    
    # ç¿»è¨³ã®å¿…è¦æ€§ã‚’è¡¨ç¤ºï¼ˆäº‹å‰åˆ¤å®šï¼‰
    if source_language == target_language:
        st.success("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å…ƒã®å“è³ªã‚’ä¿ã¡ã¾ã™ï¼ˆåŒã˜è¨€èªï¼‰")
    elif source_language == "auto":
        st.info("ğŸ” è‡ªå‹•æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ï¼šæ¤œå‡ºã•ã‚ŒãŸè¨€èªã«ã‚ˆã£ã¦ç¿»è¨³ã‚’åˆ¤å®šã—ã¾ã™")
        st.caption(f"â†’ æ—¥æœ¬èªãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆï¼šç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå“è³ªä¿æŒï¼‰")
        st.caption(f"â†’ ä»–ã®è¨€èªãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆï¼š{TARGET_LANGUAGES[target_language]}ã«ç¿»è¨³")
    elif source_language == "unknown":
        st.info("â“ è¨€èªä¸æ˜ãƒ¢ãƒ¼ãƒ‰ï¼šæ¤œå‡ºã•ã‚ŒãŸè¨€èªã«ã‚ˆã£ã¦ç¿»è¨³ã‚’åˆ¤å®šã—ã¾ã™")
    else:
        source_name = LANGUAGES.get(source_language, "ä¸æ˜")
        target_name = TARGET_LANGUAGES.get(target_language, "ä¸æ˜")
        if source_language == "ja" and target_language == "ja":
            st.success("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å…ƒã®å“è³ªã‚’ä¿ã¡ã¾ã™ï¼ˆæ—¥æœ¬èªâ†’æ—¥æœ¬èªï¼‰")
        else:
            st.info(f"ğŸŒ {source_name} â†’ {target_name} ã«ç¿»è¨³ã—ã¾ã™")
    
    # å­—å¹•è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    with st.expander("ğŸ¨ å­—å¹•ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š"):
        col1, col2 = st.columns(2)
        
        with col1:
            font_size = st.slider("ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º", 12, 24, 16)
            max_chars_per_line = st.slider("1è¡Œã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°", 15, 30, 20)
        
        with col2:
            margin_bottom = st.slider("ä¸‹ç«¯ã‹ã‚‰ã®ä½™ç™½", 10, 50, 20)
            max_lines = st.selectbox("æœ€å¤§è¡Œæ•°", [1, 2], index=1)
            outline_width = st.slider("ç¸å–ã‚Šå¤ªã•", 1, 4, 2)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['mp4', 'mov', 'avi', 'mkv'],
        help="å¯¾å¿œå½¢å¼: MP4, MOV, AVI, MKV"
    )
    
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        with tempfile.TemporaryDirectory() as temp_dir:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»ã‚’ä¿å­˜
            video_path = os.path.join(temp_dir, "input_video.mp4")
            with open(video_path, "wb") as f:
                f.write(uploaded_file.read())
            
            # å‹•ç”»æƒ…å ±è¡¨ç¤º
            st.video(uploaded_file)
            
            if st.button("ğŸš€ å­—å¹•ç”Ÿæˆé–‹å§‹"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Step 1: éŸ³å£°æŠ½å‡º
                status_text.text("ğŸ“„ å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
                progress_bar.progress(20)
                
                audio_path = os.path.join(temp_dir, "audio.wav")
                if not extract_audio_from_video(video_path, audio_path):
                    st.stop()
                
                # Step 2: éŸ³å£°èªè­˜
                status_text.text("ğŸ¤ éŸ³å£°èªè­˜ä¸­...")
                progress_bar.progress(40)
                
                transcript = transcribe_with_whisper(audio_path, source_language)
                if not transcript:
                    st.stop()
                
                # Step 3: ç¿»è¨³åˆ¤å®šã¨å®Ÿè¡Œ
                status_text.text("ğŸŒ ç¿»è¨³åˆ¤å®šä¸­...")
                progress_bar.progress(60)
                
                original_text = transcript.text if hasattr(transcript, 'text') else ''
                
                # WhisperãŒå®Ÿéš›ã«æ¤œå‡ºã—ãŸè¨€èªã‚’å–å¾—
                detected_language = getattr(transcript, 'language', source_language)
                
                # è‡ªå‹•æ¤œå‡ºã®å ´åˆã¯ã€å®Ÿéš›ã«æ¤œå‡ºã•ã‚ŒãŸè¨€èªã‚’ä½¿ç”¨
                actual_source_lang = detected_language if source_language == "auto" else source_language
                
                # ç¿»è¨³ã®å¿…è¦æ€§ã‚’åˆ¤å®šï¼ˆå®Ÿéš›ã®æ¤œå‡ºè¨€èªãƒ™ãƒ¼ã‚¹ï¼‰
                need_translation = not (
                    actual_source_lang == target_language or
                    (actual_source_lang == "ja" and target_language == "ja") or
                    (actual_source_lang == "japanese" and target_language == "ja")  # Whisperã¯"japanese"ã‚’è¿”ã™ã“ã¨ãŒã‚ã‚‹
                )
                
                # æ¤œå‡ºã•ã‚ŒãŸè¨€èªã‚’è¡¨ç¤º
                if source_language == "auto":
                    detected_lang_name = LANGUAGES.get(detected_language, detected_language)
                    st.info(f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸè¨€èª: {detected_lang_name} ({detected_language})")
                
                if need_translation:
                    status_text.text("ğŸŒ ç¿»è¨³ä¸­...")
                    translated_text = translate_with_claude(original_text, actual_source_lang, target_language)
                    source_display = LANGUAGES.get(actual_source_lang, actual_source_lang)
                    target_display = TARGET_LANGUAGES.get(target_language, target_language)
                    st.info(f"âœ¨ {source_display} â†’ {target_display} ã«ç¿»è¨³ã—ã¾ã—ãŸ")
                else:
                    status_text.text("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å“è³ªã‚’ä¿æŒ...")
                    translated_text = original_text
                    st.info(f"âœ¨ æ¤œå‡ºè¨€èªã¨ç¿»è¨³å…ˆãŒåŒã˜ï¼ˆ{LANGUAGES.get(actual_source_lang, actual_source_lang)}ï¼‰ã®ãŸã‚ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€å…ƒã®å“è³ªã‚’ä¿æŒã—ã¾ã—ãŸ")
                
                # Step 4: å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                status_text.text("ğŸ“ å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
                progress_bar.progress(80)
                
                # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’é©ç”¨
                srt_content = create_srt_from_transcript_custom(
                    transcript, translated_text, source_language, target_language,
                    max_chars_per_line, max_lines
                )
                srt_path = os.path.join(temp_dir, "subtitles.srt")
                srt_content.save(srt_path)
                
                # Step 5: å‹•ç”»ã«å­—å¹•åŸ‹ã‚è¾¼ã¿
                status_text.text("ğŸ¬ å‹•ç”»ã«å­—å¹•ã‚’åŸ‹ã‚è¾¼ã¿ä¸­...")
                progress_bar.progress(90)
                
                output_path = os.path.join(temp_dir, "output_with_subtitles.mp4")
                if embed_subtitles_to_video_custom(video_path, srt_path, output_path, font_size, margin_bottom, outline_width):
                    progress_bar.progress(100)
                    status_text.text("âœ… å®Œäº†ï¼")
                    
                    # çµæœè¡¨ç¤º
                    st.success("å­—å¹•ä»˜ãå‹•ç”»ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if source_language == "auto":
                            detected_lang_name = LANGUAGES.get(detected_language, detected_language)
                            st.subheader(f"ğŸ“„ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ (æ¤œå‡º: {detected_lang_name})")
                        else:
                            st.subheader(f"ğŸ“„ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ ({LANGUAGES[source_language]})")
                        st.text_area("", original_text, height=200, key="original")
                    
                    with col2:
                        if need_translation:
                            st.subheader(f"ğŸŒ ç¿»è¨³çµæœ ({TARGET_LANGUAGES[target_language]})")
                            st.text_area("", translated_text, height=200, key="translated")
                        else:
                            st.subheader(f"âœ¨ çµæœ ({TARGET_LANGUAGES[target_language]})")
                            st.text_area("", translated_text, height=200, key="translated")
                            st.caption("ç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå“è³ªä¿æŒï¼‰")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    with open(output_path, "rb") as f:
                        st.download_button(
                            label="ğŸ“¥ å­—å¹•ä»˜ãå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=f.read(),
                            file_name="subtitled_video.mp4",
                            mime="video/mp4"
                        )
                    
                    # SRTãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    with open(srt_path, "r", encoding="utf-8") as f:
                        st.download_button(
                            label="ğŸ“„ å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«(SRT)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=f.read(),
                            file_name="subtitles.srt",
                            mime="text/plain"
                        )

with tab2:
    st.write("ãƒã‚¤ã‚¯ã‚’ä½¿ã£ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ»ç¿»è¨³ã‚’è¡Œã„ã¾ã™")
    
    # è¨€èªè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("âš™ï¸ è¨€èªè¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        rt_source_language = st.selectbox(
            "å…ƒã®è¨€èªï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰",
            list(LANGUAGES.keys()),
            format_func=lambda x: LANGUAGES[x],
            index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ—¥æœ¬èª
            key="rt_source"
        )
    
    with col2:
        rt_target_language = st.selectbox(
            "ç¿»è¨³å…ˆè¨€èªï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰",
            list(TARGET_LANGUAGES.keys()),
            format_func=lambda x: TARGET_LANGUAGES[x],
            index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ—¥æœ¬èª
            key="rt_target"
        )
    
    # ç¿»è¨³ã®å¿…è¦æ€§ã‚’è¡¨ç¤º
    if rt_source_language == rt_target_language:
        st.success("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å…ƒã®å“è³ªã‚’ä¿ã¡ã¾ã™ï¼ˆåŒã˜è¨€èªï¼‰")
    elif rt_source_language == "auto":
        st.info("ğŸ” è‡ªå‹•æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ï¼šæ¤œå‡ºã•ã‚ŒãŸè¨€èªã«ã‚ˆã£ã¦ç¿»è¨³ã‚’åˆ¤å®šã—ã¾ã™")
        st.caption(f"â†’ æ—¥æœ¬èªãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆï¼šç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå“è³ªä¿æŒï¼‰")
        st.caption(f"â†’ ä»–ã®è¨€èªãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆï¼š{TARGET_LANGUAGES[rt_target_language]}ã«ç¿»è¨³")
    elif rt_source_language == "unknown":
        st.info("â“ è¨€èªä¸æ˜ãƒ¢ãƒ¼ãƒ‰ï¼šæ¤œå‡ºã•ã‚ŒãŸè¨€èªã«ã‚ˆã£ã¦ç¿»è¨³ã‚’åˆ¤å®šã—ã¾ã™")
    else:
        source_name = LANGUAGES.get(rt_source_language, "ä¸æ˜")
        target_name = TARGET_LANGUAGES.get(rt_target_language, "ä¸æ˜")
        if rt_source_language == "ja" and rt_target_language == "ja":
            st.success("âœ¨ ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å…ƒã®å“è³ªã‚’ä¿ã¡ã¾ã™ï¼ˆæ—¥æœ¬èªâ†’æ—¥æœ¬èªï¼‰")
        else:
            st.info(f"ğŸŒ {source_name} â†’ {target_name} ã«ç¿»è¨³ã—ã¾ã™")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ã‚’æ˜ç¢ºã«è¡Œã†
    if 'recording_active' not in st.session_state:
        st.session_state.recording_active = False
    
    if 'transcription_history' not in st.session_state:
        st.session_state.transcription_history = []
    
    # ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
    st.subheader("ğŸ¤ ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”§ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"):
            try:
                import pyaudio
                audio = pyaudio.PyAudio()
                
                # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                device_count = audio.get_device_count()
                st.success(f"âœ… PyAudioæ­£å¸¸å‹•ä½œ: {device_count}å€‹ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒã‚¤ã‚¯ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    stream = audio.open(
                        format=pyaudio.paInt16,
                        channels=1,
                        rate=16000,
                        input=True,
                        frames_per_buffer=1024
                    )
                    stream.close()
                    st.success("âœ… ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸï¼éŒ²éŸ³æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                except Exception as mic_error:
                    st.error(f"âŒ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {mic_error}")
                    st.info("ğŸ’¡ Macã®å ´åˆ: ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ > ãƒã‚¤ã‚¯ ã§ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                
                audio.terminate()
                
            except ImportError:
                st.error("âŒ pyaudioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                st.code("pip install pyaudio")
            except Exception as e:
                st.error(f"âŒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    with col2:
        if st.button("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ†ã‚¹ãƒˆ"):
            test_realtime_audio()
    
    st.subheader("ğŸ™ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³")
    
    # ç°¡å˜ãªéŒ²éŸ³åˆ¶å¾¡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", disabled=st.session_state.recording_active, key="start_recording"):
            try:
                st.session_state.recording_active = True
                st.success("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                # st.rerun() ã‚’å‰Šé™¤ã—ã¦å±¥æ­´ã‚’ä¿æŒ
            except Exception as e:
                st.error(f"éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.recording_active = False
    
    with col2:
        if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢", disabled=not st.session_state.recording_active, key="stop_recording"):
            st.session_state.recording_active = False
            st.success("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            # å±¥æ­´ã‚’ä¿æŒã—ãŸã¾ã¾ç”»é¢æ›´æ–°
            # st.rerun() ã‚’å‰Šé™¤ã—ã¦å±¥æ­´ã‚’ä¿æŒ
    
    with col3:
        if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚¯ãƒªã‚¢"):
            st.session_state.transcription_history = []
            st.success("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            # st.rerun() ã‚’å‰Šé™¤
    
    # éŒ²éŸ³çŠ¶æ…‹ã®è¡¨ç¤º
    if st.session_state.recording_active:
        st.info("ğŸ¤ éŒ²éŸ³ä¸­... éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦ã„ã¾ã™")
        
        # ç¾åœ¨ã®å±¥æ­´æ•°ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        st.write(f"ç¾åœ¨ã®å±¥æ­´æ•°: {len(st.session_state.transcription_history)}")
    
    # éŸ³å£°å‡¦ç†ãƒœã‚¿ãƒ³ï¼ˆéŒ²éŸ³çŠ¶æ…‹ã«é–¢ä¿‚ãªãå¸¸ã«è¡¨ç¤ºï¼‰
    st.subheader("ğŸ™ï¸ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£")
    
    if st.button("ğŸ“ æ‰‹å‹•ã§éŸ³å£°å‡¦ç†", key="manual_process"):
        try:
            with st.spinner("éŸ³å£°ã‚’å‡¦ç†ä¸­..."):
                # 5ç§’é–“ã®éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆè¨€èªè¨­å®šã‚’æ¸¡ã™ï¼‰
                success = capture_audio_chunk(rt_source_language, rt_target_language)
                if success:
                    st.success("éŸ³å£°å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    # å‡¦ç†å¾Œã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¼·åˆ¶æ›´æ–°
                    st.session_state._last_update = time.time()
                else:
                    st.error("éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    st.caption("ğŸ’¡ ã“ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨5ç§’é–“éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦æ–‡å­—èµ·ã“ã—ã—ã¾ã™")
    
    # å±¥æ­´æ•°ã®è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦è©³ç´°è¡¨ç¤ºï¼‰
    history_count = len(st.session_state.transcription_history)
    st.metric("ğŸ“Š ç·å±¥æ­´æ•°", history_count)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
        st.write("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹:")
        st.write(f"- recording_active: {st.session_state.recording_active}")
        st.write(f"- transcription_history length: {len(st.session_state.transcription_history)}")
        if st.session_state.transcription_history:
            st.write("æœ€æ–°ã®å±¥æ­´:")
            st.json(st.session_state.transcription_history[-1])
    
    # éŸ³å£°èªè­˜çµæœã®è¡¨ç¤ºï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
    if history_count > 0:
        st.subheader("ğŸ“ éŸ³å£°èªè­˜çµæœ")
        
        # æœ€æ–°ã®çµæœã‚’æœ€åˆã«è¡¨ç¤ºï¼ˆæœ€æ–°ã‚’è‡ªå‹•å±•é–‹ï¼‰
        for i, entry in enumerate(reversed(st.session_state.transcription_history[-10:])):  # æœ€æ–°10ä»¶
            result_number = history_count - i
            is_latest = (i == 0)  # æœ€æ–°ã®çµæœ
            
            # ç¿»è¨³æƒ…å ±ã®è¡¨ç¤º
            translation_info = ""
            if entry.get('was_translated', True):  # å¤ã„ãƒ‡ãƒ¼ã‚¿ã¯ç¿»è¨³ã‚ã‚Šã¨ã—ã¦æ‰±ã†
                source_lang = entry.get('source_lang', 'ä¸æ˜')
                target_lang = entry.get('target_lang', TARGET_LANGUAGES[rt_target_language])
                translation_info = f" ({source_lang}â†’{target_lang})"
            else:
                translation_info = " (ç¿»è¨³ãªã—)"
            
            with st.expander(
                f"[{entry['timestamp']}] çµæœ #{result_number}{translation_info} {'(æœ€æ–°)' if is_latest else ''}",
                expanded=is_latest  # æœ€æ–°ã®çµæœã®ã¿å±•é–‹
            ):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**å…ƒã®éŸ³å£°:**")
                    st.write(entry['original'])
                    if 'detected_lang' in entry and entry.get('detected_lang'):
                        st.caption(f"æ¤œå‡ºè¨€èª: {entry.get('source_lang', 'ä¸æ˜')} ({entry['detected_lang']})")
                    elif 'source_lang' in entry:
                        st.caption(f"èªè­˜è¨€èª: {entry['source_lang']}")
                with col2:
                    if entry.get('was_translated', True):
                        st.write("**ç¿»è¨³çµæœ:**")
                        st.write(entry['translated'])
                        if 'target_lang' in entry:
                            st.caption(f"ç¿»è¨³å…ˆ: {entry['target_lang']}")
                    else:
                        st.write("**çµæœ:**")
                        st.write(entry['translated'])
                        st.caption("ç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå“è³ªä¿æŒï¼‰")
        
        # å…¨å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¥ å…¨å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                history_text = f"éŸ³å£°èªè­˜å±¥æ­´ (ç·æ•°: {history_count})\n"
                history_text += f"ç”Ÿæˆæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                
                for i, entry in enumerate(st.session_state.transcription_history, 1):
                    history_text += f"=== çµæœ #{i} ===\n"
                    history_text += f"æ™‚åˆ»: {entry['timestamp']}\n"
                    history_text += f"å…ƒã®éŸ³å£°: {entry['original']}\n"
                    
                    # è¨€èªæƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                    if 'detected_lang' in entry and entry.get('detected_lang'):
                        history_text += f"æ¤œå‡ºè¨€èª: {entry.get('source_lang', 'ä¸æ˜')} ({entry['detected_lang']})\n"
                    elif 'source_lang' in entry:
                        history_text += f"èªè­˜è¨€èª: {entry['source_lang']}\n"
                    
                    # ç¿»è¨³æƒ…å ±
                    if entry.get('was_translated', True):
                        history_text += f"ç¿»è¨³çµæœ: {entry['translated']}\n"
                        if 'target_lang' in entry:
                            history_text += f"ç¿»è¨³å…ˆè¨€èª: {entry['target_lang']}\n"
                    else:
                        history_text += f"çµæœ: {entry['translated']}\n"
                        history_text += f"ç¿»è¨³: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå“è³ªä¿æŒï¼‰\n"
                    
                    history_text += "\n"
                
                st.download_button(
                    label="ğŸ“„ å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=history_text,
                    file_name=f"transcription_history_{history_count}ä»¶.txt",
                    mime="text/plain"
                )
        
        with col2:
            if st.button("ğŸ”„ å±¥æ­´ã‚’æ›´æ–°"):
                st.success("å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    else:
        st.info("ã¾ã éŸ³å£°èªè­˜çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€ŒğŸ“ æ‰‹å‹•ã§éŸ³å£°å‡¦ç†ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦ãã ã•ã„ã€‚")
        st.write("ğŸ’¡ **æ‰‹é †:**")
        st.write("1. ğŸ¤ éŒ²éŸ³é–‹å§‹ã‚’ã‚¯ãƒªãƒƒã‚¯")
        st.write("2. ğŸ“ æ‰‹å‹•ã§éŸ³å£°å‡¦ç†ã‚’ã‚¯ãƒªãƒƒã‚¯")
        st.write("3. 5ç§’é–“è©±ã™")
        st.write("4. çµæœãŒè¡¨ç¤ºã•ã‚Œã‚‹")

# ä½¿ã„æ–¹èª¬æ˜
with st.expander("ğŸ“– ä½¿ã„æ–¹"):
    st.markdown("""
    ## ğŸ¬ å‹•ç”»å­—å¹•ç”Ÿæˆ
    1. **è¨€èªè¨­å®š**: å…ƒã®è¨€èªã¨ç¿»è¨³å…ˆè¨€èªã‚’é¸æŠ
    2. **å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: å¯¾å¿œå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    3. **å®Ÿè¡Œ**: ã€Œå­—å¹•ç”Ÿæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ç”Ÿæˆã•ã‚ŒãŸå­—å¹•ä»˜ãå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    ## ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜
    1. **ç¿»è¨³å…ˆè¨€èªé¸æŠ**: ç¿»è¨³ã—ãŸã„è¨€èªã‚’é¸æŠ
    2. **éŒ²éŸ³é–‹å§‹**: ãƒã‚¤ã‚¯ã§éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
    3. **éŒ²éŸ³åœæ­¢**: å¿…è¦ã«å¿œã˜ã¦åœæ­¢
    4. **çµæœç¢ºèª**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—ãƒ»ç¿»è¨³çµæœã‚’è¡¨ç¤º
    
    **å¯¾å¿œå½¢å¼**: MP4, MOV, AVI, MKV
    **å‡¦ç†æ™‚é–“**: å‹•ç”»ã®é•·ã•ã«å¿œã˜ã¦æ•°åˆ†ã€œæ•°ååˆ†
    """)

# æ³¨æ„äº‹é …
with st.expander("âš ï¸ æ³¨æ„äº‹é …"):
    st.markdown("""
    - **APIã‚³ã‚¹ãƒˆ**: é•·æ™‚é–“ã®å‹•ç”»ãƒ»éŸ³å£°ã¯æ–™é‡‘ãŒé«˜ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
    - **å‡¦ç†æ™‚é–“**: å‹•ç”»ã®é•·ã•ã«æ¯”ä¾‹ã—ã¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
    - **ãƒã‚¤ã‚¯è¨±å¯**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã«ã¯ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™
    - **ç²¾åº¦**: éŸ³è³ªã‚„è©±ã—æ–¹ã«ã‚ˆã‚Šèªè­˜ç²¾åº¦ãŒå¤‰ã‚ã‚Šã¾ã™
    - **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™
    """)
